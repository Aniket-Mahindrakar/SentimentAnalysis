{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import compress\n",
    "\n",
    "import gzip\n",
    "import gensim\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_sample = pd.read_json('../Data/yelp_academic_dataset_review.json', lines = True, chunksize = 100000).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_sample = reviews_sample[['text', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sample = pd.read_csv('./Data/reviews_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  As someone who has worked with many museums, I...      2\n",
       "1  I am actually horrified this place is still in...      1\n",
       "2  I love Deagan's. I do. I really do. The atmosp...      5\n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...      1\n",
       "4  Oh happy day, finally have a Canes near my cas...      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "processed_text = reviews_sample['text'].map(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "processed_text = processed_text.str.lower()\n",
    "\n",
    "reviews_sample['tokens'] = processed_text.map(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sample['tokens'] = reviews_sample['tokens'].map(lambda x: [ps.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As someone who has worked with many museums, I was eager to visit this gallery on my most recent trip to Las Vegas. When I saw they would be showing infamous eggs of the House of Faberge from the Virginia Museum of Fine Arts (VMFA), I knew I had to go!\\n\\nTucked away near the gelateria and the garden, the Gallery is pretty much hidden from view. It\\'s what real estate agents would call \"cozy\" or \"charming\" - basically any euphemism for small.\\n\\nThat being said, you can still see wonderful art at a gallery of any size, so why the two *s you ask? Let me tell you:\\n\\n* pricing for this, while relatively inexpensive for a Las Vegas attraction, is completely over the top. For the space and the amount of art you can fit in there, it is a bit much.\\n* it\\'s not kid friendly at all. Seriously, don\\'t bring them.\\n* the security is not trained properly for the show. When the curating and design teams collaborate for exhibitions, there is a definite flow. That means visitors should view the art in a certain sequence, whether it be by historical period or cultural significance (this is how audio guides are usually developed). When I arrived in the gallery I could not tell where to start, and security was certainly not helpful. I was told to \"just look around\" and \"do whatever.\" \\n\\nAt such a *fine* institution, I find the lack of knowledge and respect for the art appalling.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sample['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 20:35:44,725 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2020-09-01 20:35:44,731 : INFO : collecting all words and their counts\n",
      "2020-09-01 20:35:44,732 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-09-01 20:35:44,982 : INFO : collected 22954 word types from a corpus of 1056036 raw words and 10000 sentences\n",
      "2020-09-01 20:35:44,983 : INFO : Loading a fresh vocabulary\n",
      "2020-09-01 20:35:45,018 : INFO : effective_min_count=10 retains 4183 unique words (18% of original 22954, drops 18771)\n",
      "2020-09-01 20:35:45,019 : INFO : effective_min_count=10 leaves 1017549 word corpus (96% of original 1056036, drops 38487)\n",
      "2020-09-01 20:35:45,039 : INFO : deleting the raw counts dictionary of 22954 items\n",
      "2020-09-01 20:35:45,041 : INFO : sample=0.001 downsamples 58 most-common words\n",
      "2020-09-01 20:35:45,042 : INFO : downsampling leaves estimated 741350 word corpus (72.9% of prior 1017549)\n",
      "2020-09-01 20:35:45,061 : INFO : estimated required memory for 4183 words and 150 dimensions: 7111100 bytes\n",
      "2020-09-01 20:35:45,063 : INFO : resetting layer weights\n",
      "2020-09-01 20:35:45,150 : INFO : training model with 10 workers on 4183 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-09-01 20:35:45,790 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:45,805 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:45,806 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:45,810 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:45,813 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:45,822 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:45,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:45,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:45,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:45,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:45,839 : INFO : EPOCH - 1 : training on 1056036 raw words (741045 effective words) took 0.7s, 1092546 effective words/s\n",
      "2020-09-01 20:35:46,452 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:46,461 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:46,462 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:46,468 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:46,472 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:46,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:46,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:46,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:46,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:46,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:46,495 : INFO : EPOCH - 2 : training on 1056036 raw words (740845 effective words) took 0.6s, 1150336 effective words/s\n",
      "2020-09-01 20:35:47,109 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:47,121 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:47,122 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:47,123 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:47,128 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:47,131 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:47,143 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:47,147 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:47,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:47,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:47,157 : INFO : EPOCH - 3 : training on 1056036 raw words (741255 effective words) took 0.7s, 1137073 effective words/s\n",
      "2020-09-01 20:35:47,782 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:47,798 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:47,798 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:47,803 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:47,805 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:47,809 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:47,818 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:47,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:47,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:47,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:47,833 : INFO : EPOCH - 4 : training on 1056036 raw words (741174 effective words) took 0.7s, 1115786 effective words/s\n",
      "2020-09-01 20:35:48,463 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:48,470 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:48,471 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:48,480 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:48,482 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:48,486 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:48,492 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:48,498 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:48,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:48,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:48,506 : INFO : EPOCH - 5 : training on 1056036 raw words (741395 effective words) took 0.7s, 1126872 effective words/s\n",
      "2020-09-01 20:35:49,125 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:49,138 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:49,142 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:49,149 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:49,155 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:49,161 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:49,167 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:49,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:49,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:49,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:49,179 : INFO : EPOCH - 6 : training on 1056036 raw words (741335 effective words) took 0.7s, 1122112 effective words/s\n",
      "2020-09-01 20:35:49,788 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:49,805 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:49,808 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:49,811 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:49,820 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:49,827 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:49,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-01 20:35:49,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:49,841 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:49,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:49,845 : INFO : EPOCH - 7 : training on 1056036 raw words (741144 effective words) took 0.7s, 1126910 effective words/s\n",
      "2020-09-01 20:35:50,468 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:50,484 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:50,485 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:50,487 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:50,491 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:50,496 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:50,508 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:50,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:50,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:50,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:50,518 : INFO : EPOCH - 8 : training on 1056036 raw words (740731 effective words) took 0.7s, 1117625 effective words/s\n",
      "2020-09-01 20:35:51,184 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:51,196 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:51,201 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:51,208 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:51,213 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:51,221 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:51,226 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:51,229 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:51,236 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:51,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:51,238 : INFO : EPOCH - 9 : training on 1056036 raw words (741578 effective words) took 0.7s, 1044980 effective words/s\n",
      "2020-09-01 20:35:51,895 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-09-01 20:35:51,914 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-09-01 20:35:51,915 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-09-01 20:35:51,916 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-09-01 20:35:51,921 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-01 20:35:51,927 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-01 20:35:51,935 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-01 20:35:51,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-01 20:35:51,946 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-01 20:35:51,947 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-01 20:35:51,948 : INFO : EPOCH - 10 : training on 1056036 raw words (741050 effective words) took 0.7s, 1059990 effective words/s\n",
      "2020-09-01 20:35:51,949 : INFO : training on a 10560360 raw words (7411552 effective words) took 6.8s, 1090404 effective words/s\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(\n",
    "    reviews_sample['tokens'],\n",
    "    size = 150,\n",
    "    window = 10,\n",
    "    min_count = 10,\n",
    "    workers = 10,\n",
    "    iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embeddings(sentence):\n",
    "    sum = 0\n",
    "\n",
    "    for i in sentence:\n",
    "        if i in word2vec_model.wv:\n",
    "            sum += word2vec_model[i]\n",
    "        else:\n",
    "            pass\n",
    "    return (sum / len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "reviews_sample['embeddings'] = reviews_sample['tokens'].map(lambda x: sentence_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>2</td>\n",
       "      <td>[as, someon, who, ha, work, with, mani, museum...</td>\n",
       "      <td>[0.04896843, 0.0020875202, -0.06508564, -0.162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, am, actual, horrifi, thi, place, is, still...</td>\n",
       "      <td>[-0.08957768, 0.0099274125, 0.027014272, -0.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>5</td>\n",
       "      <td>[i, love, deagan, i, do, i, realli, do, the, a...</td>\n",
       "      <td>[0.5666534, -0.47904688, 0.14099196, 0.2800023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dismal, lukewarm, defrostedtast, texmex, glop...</td>\n",
       "      <td>[-0.11999621, -0.17503685, -0.43339938, -0.413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>4</td>\n",
       "      <td>[oh, happi, day, final, have, a, cane, near, m...</td>\n",
       "      <td>[0.030274257, -0.13174579, -0.07064431, -0.271...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  \\\n",
       "0  As someone who has worked with many museums, I...      2   \n",
       "1  I am actually horrified this place is still in...      1   \n",
       "2  I love Deagan's. I do. I really do. The atmosp...      5   \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...      1   \n",
       "4  Oh happy day, finally have a Canes near my cas...      4   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [as, someon, who, ha, work, with, mani, museum...   \n",
       "1  [i, am, actual, horrifi, thi, place, is, still...   \n",
       "2  [i, love, deagan, i, do, i, realli, do, the, a...   \n",
       "3  [dismal, lukewarm, defrostedtast, texmex, glop...   \n",
       "4  [oh, happi, day, final, have, a, cane, near, m...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.04896843, 0.0020875202, -0.06508564, -0.162...  \n",
       "1  [-0.08957768, 0.0099274125, 0.027014272, -0.22...  \n",
       "2  [0.5666534, -0.47904688, 0.14099196, 0.2800023...  \n",
       "3  [-0.11999621, -0.17503685, -0.43339938, -0.413...  \n",
       "4  [0.030274257, -0.13174579, -0.07064431, -0.271...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_sample[['text', 'tokens', 'embeddings']], reviews_sample['stars'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(random_state=0)\n",
    "model.fit(X_train['embeddings'].tolist(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test['embeddings'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909090909090909"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 381,   12,   11,   22,   48],\n",
       "       [ 133,   13,   31,   68,   60],\n",
       "       [  58,   13,   43,  182,   74],\n",
       "       [  31,    4,   24,  300,  407],\n",
       "       [  32,    3,    7,  130, 1213]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_samples = pd.concat([X_test[y_pred != y_test], y_test[y_pred != y_test]], axis=1)\n",
    "misclassified_samples['pred_stars'] = list(compress(y_pred, y_pred!=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>actual_stars</th>\n",
       "      <th>pred_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4742</td>\n",
       "      <td>I'm not sure what to make of the previous revi...</td>\n",
       "      <td>[im, not, sure, what, to, make, of, the, previ...</td>\n",
       "      <td>[0.15715837, -0.13592465, 0.06248431, -0.19514...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4521</td>\n",
       "      <td>Decent flavour, similar to osmows chicken on t...</td>\n",
       "      <td>[decent, flavour, similar, to, osmow, chicken,...</td>\n",
       "      <td>[0.3326968, -0.51136875, -0.018689208, 0.16595...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5202</td>\n",
       "      <td>Please run here... do not walk, run!  Do not l...</td>\n",
       "      <td>[pleas, run, here, do, not, walk, run, do, not...</td>\n",
       "      <td>[0.069528416, -0.080433734, 0.2995614, -0.0756...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7487</td>\n",
       "      <td>Great independent coffee and pastry spot in th...</td>\n",
       "      <td>[great, independ, coffe, and, pastri, spot, in...</td>\n",
       "      <td>[0.5939762, -0.052089486, -0.273092, -0.467294...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3999</td>\n",
       "      <td>A nice little quaint Italian restaurant. It's ...</td>\n",
       "      <td>[a, nice, littl, quaint, italian, restaur, it,...</td>\n",
       "      <td>[0.76967317, -0.45733434, -0.279508, -0.065599...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "4742  I'm not sure what to make of the previous revi...   \n",
       "4521  Decent flavour, similar to osmows chicken on t...   \n",
       "5202  Please run here... do not walk, run!  Do not l...   \n",
       "7487  Great independent coffee and pastry spot in th...   \n",
       "3999  A nice little quaint Italian restaurant. It's ...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "4742  [im, not, sure, what, to, make, of, the, previ...   \n",
       "4521  [decent, flavour, similar, to, osmow, chicken,...   \n",
       "5202  [pleas, run, here, do, not, walk, run, do, not...   \n",
       "7487  [great, independ, coffe, and, pastri, spot, in...   \n",
       "3999  [a, nice, littl, quaint, italian, restaur, it,...   \n",
       "\n",
       "                                             embeddings  actual_stars  \\\n",
       "4742  [0.15715837, -0.13592465, 0.06248431, -0.19514...             2   \n",
       "4521  [0.3326968, -0.51136875, -0.018689208, 0.16595...             3   \n",
       "5202  [0.069528416, -0.080433734, 0.2995614, -0.0756...             5   \n",
       "7487  [0.5939762, -0.052089486, -0.273092, -0.467294...             4   \n",
       "3999  [0.76967317, -0.45733434, -0.279508, -0.065599...             4   \n",
       "\n",
       "      pred_stars  \n",
       "4742           1  \n",
       "4521           4  \n",
       "5202           1  \n",
       "7487           5  \n",
       "3999           5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_samples = misclassified_samples.rename(columns={'stars': 'actual_stars'})\n",
    "misclassified_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature additions to detect polarity\n",
    "\n",
    "reviews_sample[['num_exclamation', 'stars']].groupby(['stars']).mean()\n",
    "reviews_sample['percent_UPPER'] = reviews_sample['text'].map(lambda x: len(re.findall(r'[A-Z]', x)) / len(x))\n",
    "reviews_sample['frowny'] = reviews_sample['text'].map(lambda x: len(re.findall(':\\(', x)) + len(re.findall(':-\\(', x)))\n",
    "\n",
    "\n",
    "# feature additions to detect positive vs negative\n",
    "\n",
    "reviews_sample['len_review'] = reviews_sample['text'].map(lambda x: len(x.split(' ')))\n",
    "reviews_sample['smiley'] = reviews_sample['text'].map(lambda x: len(re.findall(':\\)', x)) + len(re.findall(':-\\)', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
